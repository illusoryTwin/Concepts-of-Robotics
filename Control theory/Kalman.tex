
\section{Kalman Filter} 

Kalman Filter is a powerful algorithm that 
the Kalman Filter is a generic algorithm that is used to estimate system parameters. 


It can use inaccurate or noisy measurements to estimate the state of that variable 
or another unobservable variable with greater accuracy.



Assume that the DT LTI system dynamics takes the form: 
\[x-{i+1} = Ax_i + Bu_i + w_i\]
$w_i$ is the random noise which satisfies the Gaussian distribution. 

\subsection{Open-loop observer}
Let's propose an open-loop observer

\[\hat x-{i+1} = A \hat x_i + Bu_i\]

The estimation error is as follows:
\[\tilde{x}_{i+1} = A \tilde{x}_i + w_i\]

We can compute the mean error \(E[\tilde{x}_{i+1}]\):
\[E[\tilde{x}_{i+1}] = E[A \tilde{x}_i + w_i] = AE[\tilde{x}_i]\]

If we pick such an initial state that \(E[\tilde{x}_i] = 0\), then the state estimation dynamics would be 0 too.

Knowing the autocovariance \(P_i\), we can compute \(P_{i+1}\):
\[
P_{i+1} = E[\tilde{x}_{i+1} \tilde{x}_{i+1}^T] = E[(A \tilde{x}_i + w_i)(A \tilde{x}_i + w_i)^T] \\
= E[A \tilde{x}_i \tilde{x}_i^T A^T + A \tilde{x}_i w_i^T + w_i \tilde{x}_i^T A^T + w_i w_i^T]
\]

We can assume that the random process \(w\) is uncorrelated with \(\tilde{x}\), so 
\[ E[\tilde{x}_i w_i^T] = E[w_i \tilde{x}_i^T] = 0 \]
\[ P_{i+1} = E[A \tilde{x}_i \tilde{x}_i^T A^T + w_i w_i^T] = AP_iA^T + Q \]

\subsection{Closed-loop observer}
\[
\begin{cases}
    \hat{x}_{i+1}^- = A \hat{x}_i + Bu_i \\
    \hat{x}_{i+1} = \hat{x}_{i+1}^- + L(y_i - H \hat{x}_{i+1}^-)
\end{cases}
\] 

Let's subtract \(x_{i+1}\) from the second equation of the system.

\[
\hat{x}_{i+1} - x_{i+1} = \hat{x}_{i+1}^- - x_{i+1} + L(y_i - H \hat{x}_{i+1}^-)
\]

\[
\hat{x}_{i+1} - x_{i+1} = \hat{x}_{i+1}^- - x_{i+1} + L(Hx_i + v_i - H \hat{x}_{i+1}^-)
\]

Note that \(\tilde{x}_{i+1} = \hat{x}_{i+1} - x_{i+1}\) and \(\tilde{x}_{i+1}^- = \hat{x}_{i+1}^- - x_{i+1}\)

\[
\tilde{x}_{i+1} = \tilde{x}_{i+1}^- + L(Hx_i + v_i - H \hat{x}_{i+1}^-)
\]


From the equation \(x_{i+1} = A x_i + B u_i + w_i\), let's subtract the first equation of the system, we get: 
\[ x_{i+1} - \hat x_{i+1}^- = A x_i + Bu_i + w_i  - A \hat x_i - Bu_i\]

\[ x_{i+1} - \hat x_{i+1}^- = A x_i + Bu_i + w_i - A \hat x_i - Bu_i\]


Thus, we get the system of equations:
\[
\begin{cases}
    \Tilde x_{i+1}^- = A \Tilde x_i + w_i\\
    \Tilde x_{i+1} = (I - L_i H)\Tilde x_{i+1}^- - L_i v_i
\end{cases}
\]



Now let's compute the estimation error mean dynamics. 

\[
E[\Tilde{x}_{i+1}^-] = E[A \Tilde{x}_i + w_i] = E[A \Tilde{x}_i] + E[w_i] = AE[\Tilde{x}_i]
\]

\[
E[\Tilde{x}_{i+1}] = E[(I - L_i H)\Tilde{x}_{i+1}^- + L_i v_i] = E[(I - L_i H)\Tilde{x}_{i+1}^-] = (I - L_i H)E[\Tilde{x}_{i+1}^-]
\]

So, 
\[
\begin{cases}
    E[\Tilde{x}_{i+1}^-] = AE[\Tilde{x}_i] \\
    E[\Tilde{x}_{i+1}] = (I - L_i H)E[\Tilde{x}_{i+1}^-] 
\end{cases}
\]

\subsubsection{A priori estimation error covariance}

\[
E[\Tilde{x}_{i+1}^- (\Tilde{x}_{i+1}^-)^T] = E[(A \Tilde{x}_i + w_i)(A \Tilde{x}_i + w_i)^T] = AP_iA^T + Q_i
\]

\subsubsection{A posteriori estimation error covariance}
\[
\begin{aligned}
P_{i+1} = E[\Tilde{x}_{i+1} (\Tilde{x}_{i+1})^T] &= E\left[ \left( (I-L_i H) \Tilde{x}_{i+1}^- + L_i v_i \right) \left( (I-L_i H) \Tilde{x}_{i+1}^- + L_i v_i \right)^T \right] \\
&= E\left[ (I-L_i H) \Tilde{x}_{i+1}^- (\Tilde{x}_{i+1}^-)^T (I -L_i H)^T + (I- L_i H) \Tilde{x}_{i+1}^- v_i^T \right. \\
& \quad \left. + v_i (\Tilde{x}_{i+1}^-)^T (I-L_i H)^T + L_i v_i v_i^T L_i^T \right]
\end{aligned}
\]

\subsection{Kalman Filter Gain}

The global task is to lower the influence of noise on our system. To optimize 

We attempt to optimize $L_i$ (or to derive the optimal Kalman gain) while minimizing the mean error.

The cost function J:
\[
\begin{aligned}
J &= E \left[ \sum \Tilde{x}_{i+1}^2 \right] = E\left[\text{tr}(\Tilde{x}_{i+1} \Tilde{x}_{i+1}^T)\right] = \text{tr}(E[\Tilde{x}_{i+1} \Tilde{x}_{i+1}^T]) = \text{tr}(P_{i+1}) \\
P_{i+1} &= E\left[ \left( (I-L_i H) \Tilde{x}_{i+1}^- + L_i v_i \right) \left( (I-L_i H) \Tilde{x}_{i+1}^- + L_i v_i \right)^T \right] \\
&= tr((I-L_i H) \Tilde{x}_{i+1}^- (\Tilde{x}_{i+1}^-)^T (I -L_i H)^T + (I- L_i H) \Tilde{x}_{i+1}^- v_i^T  \\
& \quad  + v_i (\Tilde{x}_{i+1}^-)^T (I-L_i H)^T + L_i v_i v_i^T L_i^T)
\end{aligned}
\]

Now let's find the derivative of \(J\) with respect to \(L_i\) and set it to zero:

\begin{align*}
    \frac{\partial J}{\partial L_i} 
    &= 
    -H P_{i+1}^- - (P_{i+1}^- H^\top)^\top + 
    2(H P_{i+1}^- H^\top + R) L_i^\top = 0 \\
    &=
    -2 H P_{i+1}^- + 2(H P_{i+1}^- H^\top + R) L_i^\top = 0 \\
    L_i (H P_{i+1}^- H^\top + R) &= P_{i+1}^- H^\top \\
    L_i &= P_{i+1}^- H^\top (H P_{i+1}^- H^\top + R)^{-1}
\end{align*}

So, the Kalman gain can be optimally chosen as 
\[
L_i = P_{i+1}^- H^\top (H P_{i+1}^- H^\top + R)^{-1}.
\]



Without a Kalman filter, if your system is not observable, you won't be able to retrieve all the state variables xx from the output yy alone.
By using a Kalman filter, you can estimate all the state variables xx even if they are not all directly observable in yy. The filter uses the 
model of the system and the measurements to infer the values of the unobserved states.

% The way we pick our initial state estimate does not have a bias.

% Assume you could pick your initial state estimate $\hat x_0$ such that
% the initial state estimation error behaves as a random 
% variable sampled from a Gaussian distribution $x_0 ~ N(0, P_0)$

% Knowing mean 

% \[\]

% E[w_i] = 0

% All subsequent means will be $E[]$



% Let's compute the autocovariance $P_{i+1}$ knowing $P_i$ 

% \[P_{i+1} = E[] = E[(Ax)]\]


% We can assume thta the random process is uncorrelated with x, so 

% Since the two processes are uncorreleted then their covariance is 0.  

% \[P_{i+1} = E[A x_i x_i^T A^T + w_i w_i^T] \]

% Note that x_i^T A^T = P_i - a covariance of the previous step. 
% \[P_{i+1} = A P_i A^T + Q\]


% $v_i$ - the random noise sampled from thhe Gaussian distribution, which represents the sensor error. 
% \[v_i ~ N(0, R)\]


% $\hat x_{i+1}^-$ is the estimation before measurements - apriori estimate.

% \[x_i+1 \]

% $L_i$ is a control gain. 



% Apriori error \[x_{i+1}^- = x_{i+1} - \\hat x_{i+1}^-\]


% We claculate aposteriori covariance knowing our apriori covariance.


% The question is how to minimize those covariances.





% f we have all of the measurements
% up to and including time k available for use in our estimate of X k , then we can form
% an a posteriori estimate, which we denote as 2:. The "+" superscript denotes that
% the estimate is a posteriori. One way to form the a posteriori state estimate is to
% compute the expected value of x k conditioned on all of the measurements up to
% and including time k:
% 2; = E [ X k / y l ,y 2 , . . ., Y k ] = a posteriori estimate




% DERIVATIONOF THE DISCRETE-TIME KALMAN FILTER 125
% the estimate is a posteriori. One way to form the a posteriori state estimate is to
% compute the expected value of x k conditioned on all of the measurements up to
% and including time k:
% 2; = E [ X k / y l ,y 2 , . . ., Y k ] = a posteriori estimate (5.3)
% If we have all of the measurements before (but not including) time k available for
% use in our estimate of X k , then we can form an a praori estimate, which we denote
% as 2 ; . The "-"superscript denotes that the estimate is a priori. One way to form
% the a priori state estimate is to compute the expected value of 51, conditioned on
% all of the measurements before (but not including) time k:
% 2; = E [ X k l y l , y 2 , . ., Y k - l ] = a priori estimate (5.4)
% It is important to note that 2; and 2; are both estimates of the same quantity; they
% are both estimates of X k . However, 2 i is our estimate of Xk before the measurement
% Y k is taken into account, and 2: is our estimate of 21, after the measurement y k
% is taken into account. We naturally expect 2; to be a better estimate than 2 i ,
% because we use more information to compute 2;:
% 2 i =
% 2' k = estimate of Xk after we process the measurement at time k (5.5)
% If we have measurements after time k available for use in our estimate of X k , then
% we can form a smoothed estimate. One way to form the smoothed state estimate is
% to compute the expected value of x k conditioned on all of the measurements that
% are available:
% estimate of Xk before we process the measurement at time k
% ? k l k + N = E [ x k l Y l i Y 2 , ' . . , Y k , " ' , Y k + N ] = smoothed estimate (5.6)
% where N is some positive integer whose value depends on the specific problem that
% is being solved. If we want to find the best prediction of x k more than one time
% step ahead of the available measurements, then we can form a predicted estimate.
% One way to form the predicted state estimate is to compute the expected value of
% Xk conditioned on all of the measurements that are available:
% 2 k l k - M = E [ x k j y 1 , y 2 , - . .,y k - ~ ]= predicted estimate 